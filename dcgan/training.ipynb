{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.optim as optim\r\n",
    "import torchvision\r\n",
    "import torchvision.transforms as transformations\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "from torchvision.datasets import ImageFolder\r\n",
    "import torchvision.datasets as datasets\r\n",
    "from torch.utils.tensorboard import SummaryWriter\r\n",
    "from model import Discriminator, Generator, initialize_weights\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from utils import gradient_penalty"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# hyperparameters\r\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "LEARNING_RATE = 2e-4\r\n",
    "BATCH_SIZE = 64\r\n",
    "IMAGE_SIZE = 64\r\n",
    "CHANNELS_IMG = 3 # change according to data\r\n",
    "NOISE_DIM = 100\r\n",
    "NUM_EPOCHS = 10\r\n",
    "FEATURES_DISC = 16\r\n",
    "FEATURES_GEN = 16\r\n",
    "CRITIC_ITERATIONS = 5\r\n",
    "LAMBDA_GP = 10 # wgan-gradient penalty replaces clipping\r\n",
    "WORKERS = 6"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "transforms = transformations.Compose(\r\n",
    "    [\r\n",
    "        transformations.Resize((IMAGE_SIZE, IMAGE_SIZE)),\r\n",
    "        transformations.RandomHorizontalFlip(p=0.5),\r\n",
    "        transformations.ToTensor(),\r\n",
    "        transformations.Normalize(\r\n",
    "            [0.5 for _ in range(CHANNELS_IMG)], [0.5 for _ in range (CHANNELS_IMG)])\r\n",
    "    ]\r\n",
    ")\r\n",
    "\r\n",
    "dataset = datasets.ImageFolder('./dataset', transform=transforms)\r\n",
    "\r\n",
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=WORKERS)\r\n",
    "\r\n",
    "gen = Generator(NOISE_DIM, CHANNELS_IMG, FEATURES_GEN).to(device)\r\n",
    "critic = Discriminator(CHANNELS_IMG, FEATURES_DISC).to(device)\r\n",
    "initialize_weights(gen)\r\n",
    "initialize_weights(critic)\r\n",
    "\r\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9))\r\n",
    "opt_critic = optim.Adam(critic.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9))\r\n",
    "\r\n",
    "\r\n",
    "fixed_noise = torch.randn(32, NOISE_DIM, 1, 1).to(device)\r\n",
    "writer_real = SummaryWriter(f\"logs/real\")\r\n",
    "writer_fake = SummaryWriter(f\"logs/fake\")\r\n",
    "step = 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "'''gen = Generator(NOISE_DIM, CHANNELS_IMG, FEATURES_GEN)\r\n",
    "gen.load_state_dict(torch.load(\"./models/Generator\"))\r\n",
    "\r\n",
    "critic = Discriminator(CHANNELS_IMG, FEATURES_DISC)\r\n",
    "critic.load_state_dict(torch.load(\"./models/Critic\"))'''\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'gen = Generator(NOISE_DIM, CHANNELS_IMG, FEATURES_GEN)\\ngen.load_state_dict(torch.load(\"./models/Generator\"))\\n\\ncritic = Discriminator(CHANNELS_IMG, FEATURES_DISC)\\ncritic.load_state_dict(torch.load(\"./models/Critic\"))'"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "gen.train()\r\n",
    "critic.train()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (disc): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (5): Conv2d(128, 1, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (6): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "for epoch in range(NUM_EPOCHS):\r\n",
    "    for batch_idx, (real, _) in enumerate(loader):\r\n",
    "        real = real.to(device)\r\n",
    "        cur_batch_size = real.shape[0]\r\n",
    "\r\n",
    "        for _ in range(CRITIC_ITERATIONS):\r\n",
    "            noise = torch.randn(cur_batch_size, NOISE_DIM, 1, 1).to(device)\r\n",
    "            fake = gen(noise)\r\n",
    "            critic_real = critic(real).reshape(-1)\r\n",
    "            critic_fake = critic(fake).reshape(-1)\r\n",
    "            gp = gradient_penalty(critic, real, fake, device=device)\r\n",
    "            loss_critic = (\r\n",
    "                -(torch.mean(critic_real) - torch.mean(critic_fake)) + LAMBDA_GP * gp\r\n",
    "            )\r\n",
    "            critic.zero_grad()\r\n",
    "            loss_critic.backward(retain_graph=True)\r\n",
    "            opt_critic.step()\r\n",
    "\r\n",
    "\r\n",
    "        # Train generator\r\n",
    "        output = critic(fake).reshape(-1)\r\n",
    "        loss_gen = -torch.mean(output)\r\n",
    "        gen.zero_grad()\r\n",
    "        loss_gen.backward()\r\n",
    "        opt_gen.step()\r\n",
    "\r\n",
    "        # print losses occasionally and print to tensorboard\r\n",
    "\r\n",
    "        if batch_idx % 80 == 0 and batch_idx > 0:\r\n",
    "            print(\r\n",
    "                f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(loader)} \\\r\n",
    "                  Loss D: {loss_critic:.4f}, loss G; {loss_gen:.4f}\"\r\n",
    "            )\r\n",
    "\r\n",
    "            with torch.no_grad():\r\n",
    "                fake = gen(fixed_noise)\r\n",
    "                # take up to 32 examples\r\n",
    "                img_grid_real = torchvision.utils.make_grid(\r\n",
    "                    real[:32], normalize=True\r\n",
    "                )\r\n",
    "                img_grid_fake = torchvision.utils.make_grid(\r\n",
    "                    fake[:32], normalize=True\r\n",
    "                )\r\n",
    "\r\n",
    "                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\r\n",
    "                writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\r\n",
    "\r\n",
    "            step += 1"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch [0/10] Batch 80/329                   Loss D: 6.4264, loss G; -0.3543\n",
      "Epoch [0/10] Batch 160/329                   Loss D: 6.8600, loss G; -0.4636\n",
      "Epoch [0/10] Batch 240/329                   Loss D: 5.2296, loss G; -0.3732\n",
      "Epoch [0/10] Batch 320/329                   Loss D: 4.8994, loss G; -0.4283\n",
      "Epoch [1/10] Batch 80/329                   Loss D: 3.4745, loss G; -0.5447\n",
      "Epoch [1/10] Batch 160/329                   Loss D: 2.4740, loss G; -0.3435\n",
      "Epoch [1/10] Batch 240/329                   Loss D: 1.9236, loss G; -0.2051\n",
      "Epoch [1/10] Batch 320/329                   Loss D: 2.2354, loss G; -0.5325\n",
      "Epoch [2/10] Batch 80/329                   Loss D: 1.5609, loss G; -0.3605\n",
      "Epoch [2/10] Batch 160/329                   Loss D: 2.8049, loss G; -0.1636\n",
      "Epoch [2/10] Batch 240/329                   Loss D: 2.2533, loss G; -0.4540\n",
      "Epoch [2/10] Batch 320/329                   Loss D: 10.0522, loss G; -1.0000\n",
      "Epoch [3/10] Batch 80/329                   Loss D: 9.8545, loss G; -1.0000\n",
      "Epoch [3/10] Batch 160/329                   Loss D: 3.5816, loss G; -0.3989\n",
      "Epoch [3/10] Batch 240/329                   Loss D: 4.0134, loss G; -0.3242\n",
      "Epoch [3/10] Batch 320/329                   Loss D: 3.1494, loss G; -0.3881\n",
      "Epoch [4/10] Batch 80/329                   Loss D: 2.5130, loss G; -0.2209\n",
      "Epoch [4/10] Batch 160/329                   Loss D: 2.5972, loss G; -0.1226\n",
      "Epoch [4/10] Batch 240/329                   Loss D: 3.9689, loss G; -0.5858\n",
      "Epoch [4/10] Batch 320/329                   Loss D: 2.6308, loss G; -0.2658\n",
      "Epoch [5/10] Batch 80/329                   Loss D: 1.4084, loss G; -0.2434\n",
      "Epoch [5/10] Batch 160/329                   Loss D: 1.4509, loss G; -0.3192\n",
      "Epoch [5/10] Batch 240/329                   Loss D: 1.8038, loss G; -0.2177\n",
      "Epoch [5/10] Batch 320/329                   Loss D: 1.1175, loss G; -0.3817\n",
      "Epoch [6/10] Batch 80/329                   Loss D: 1.4358, loss G; -0.2147\n",
      "Epoch [6/10] Batch 160/329                   Loss D: 1.6714, loss G; -0.3839\n",
      "Epoch [6/10] Batch 240/329                   Loss D: 1.9818, loss G; -0.1826\n",
      "Epoch [6/10] Batch 320/329                   Loss D: 0.8589, loss G; -0.1435\n",
      "Epoch [7/10] Batch 80/329                   Loss D: 1.4967, loss G; -0.1352\n",
      "Epoch [7/10] Batch 160/329                   Loss D: 2.6542, loss G; -0.1491\n",
      "Epoch [7/10] Batch 240/329                   Loss D: 1.3998, loss G; -0.1877\n",
      "Epoch [7/10] Batch 320/329                   Loss D: 2.6150, loss G; -0.3325\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "torch.save(gen.state_dict(), \"./models/Generator\", _use_new_zipfile_serialization=False)\r\n",
    "torch.save(critic.state_dict(), \"./models/Critic\", _use_new_zipfile_serialization=False)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('pytorch': conda)"
  },
  "interpreter": {
   "hash": "8a566900cd78865d743499dea7f00735b8bf77dfcdff2131ce879e01a8a3baaa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}